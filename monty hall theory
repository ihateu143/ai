Theory:

Bayesian networks are a powerful inference tool, in which nodes represent some
random variables, edges represent dependencies and a lack of an edge between two nodes

represents a conditional independence. A powerful algorithm called the sum-product or forward-
backward algorithm allows for inference to be done on this network, calculating posteriors on

unobserved (“hidden”) variables when limited information is given. The more information is
known, the better the inference will be, but there is no requirement on the number of nodes which
must be observed. If no information is given, the marginal of the graph is trivially calculated. The
hidden and observed variables do not need to be explicitly defined when the network is set, they
simply exist based on what information is given.
Bayesian Network framework can be tested on the Monty Hall problem. The Monty Hall
problem arose from the gameshow Let’s Make a Deal, where a guest had to choose which one of
three doors had a prize behind it.
